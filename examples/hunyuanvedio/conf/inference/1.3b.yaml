engine:
  model:  /nfs/lhh/models/hunyuanveido
  loader: diffusers
  pipeline:
    class: diffusers.HunyuanVideoPipeline
    from_pretrained:
      torch_dtype: bfloat16
  components:
    vae:
      class: diffusers.AutoencoderKLHunyuanVideo
      from_pretrained:
        subfolder: vae
        torch_dtype: float32
  device: cuda
  results_path: ${experiment.exp_dir}/results
  output_format: "video"
  transformations:
    TaylorSeerTransformation:
      order: 1
      warmup_steps: 4
      skip_interval_steps: 5
      targets:
        # Matches the taylorseer official implementation at https://github.com/Shenyi-Z/TaylorSeer/tree/main/TaylorSeer-Wan2.1/wan/taylorseer/forwards
        by_name: ["*.attn","*.*ff_context*"]
      use_timestep_delta: true
    TimestepTrackerTransformation:
      {}
    StateScopeTransformation:
      {}
  state_scopes:
    ["cond", "uncond"]

generate:
  prompts: ["A cat walks on the grass, realistic"]
  negative_prompt: "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
  height: 384
  width: 512
  num_frames: 64
  guidance_scale: 5.0
  generator:
    seed: 42
    device: cuda
